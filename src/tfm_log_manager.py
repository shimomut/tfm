#!/usr/bin/env python3
"""
TFM Log Manager - Handles logging and log display functionality
"""

import sys
import threading
import logging
from datetime import datetime
from collections import deque
from dataclasses import dataclass, field
from typing import Dict, Optional
from tfm_const import LOG_TIME_FORMAT, MAX_LOG_MESSAGES
from tfm_colors import get_log_color, get_status_color
from tfm_scrollbar import draw_scrollbar, calculate_scrollbar_width
from tfm_logging_handlers import LogPaneHandler, StreamOutputHandler, RemoteMonitoringHandler, FileLoggingHandler


@dataclass
class LoggingConfig:
    """Configuration for logging system."""
    
    # Log pane settings
    log_pane_enabled: bool = True
    max_log_messages: int = 1000
    
    # Stream output settings
    stream_output_enabled: Optional[bool] = None  # None = auto-detect based on mode
    stream_output_desktop_default: bool = True
    stream_output_terminal_default: bool = False
    
    # Remote monitoring settings
    remote_monitoring_enabled: bool = False
    remote_monitoring_port: Optional[int] = None
    
    # File logging settings
    file_logging_enabled: bool = False
    file_logging_path: Optional[str] = None
    
    # Log level settings
    default_log_level: int = logging.INFO
    logger_levels: Dict[str, int] = field(default_factory=dict)
    
    # Format settings
    timestamp_format: str = "%H:%M:%S"
    message_format: str = "%(asctime)s [%(name)s] %(message)s"


class LogCapture:
    """Capture stdout/stderr and redirect to log pane with line buffering"""
    def __init__(self, source, original_stream=None, is_desktop_mode=False, logger=None):
        self.source = source
        self.original_stream = original_stream
        self.is_desktop_mode = is_desktop_mode  # Only write to original streams in desktop mode
        self.logger = logger  # Logger instance for routing through handler pipeline
        self.buffer = ""  # Line buffer - accumulates text until newline
        self.lock = threading.RLock()  # Thread safety for buffer access
        
    def write(self, text):
        with self.lock:
            # Add text to buffer
            self.buffer += text
            
            # Process complete lines (split on newlines)
            while '\n' in self.buffer:
                line, self.buffer = self.buffer.split('\n', 1)
                
                # Emit all lines, including empty ones (empty lines are meaningful output)
                self._emit_log_record(line)
    
    def _emit_log_record(self, text):
        """Emit a single log record for the given text"""
        # Route through logging infrastructure
        # INFO for stdout, WARNING for stderr
        level = logging.INFO if self.source == "STDOUT" else logging.WARNING
        
        # Requirement 11.1: Performance optimization - check if level is enabled
        # Skip expensive LogRecord creation and formatting if level is disabled
        if not self.logger.isEnabledFor(level):
            return
        
        # Create LogRecord - preserve raw text without stripping or modifying
        record = logging.LogRecord(
            name=self.source,  # "STDOUT" or "STDERR"
            level=level,
            pathname="",
            lineno=0,
            msg=text,  # Raw text, not stripped or modified
            args=(),
            exc_info=None
        )
        
        # CRITICAL: Mark this as a stream capture (not a formatted logger message)
        # Handlers will check this flag to determine formatting behavior
        record.is_stream_capture = True
        
        # Route through the logger's handler pipeline
        self.logger.handle(record)
    
    def flush(self):
        # flush() is called to ensure buffered data is written
        # However, we should NOT emit incomplete lines (lines without newline)
        # The buffer will be emitted when a newline is eventually received
        # This matches standard stream behavior where flush() doesn't add newlines
        pass


class LogManager:
    """Manages logging system and log display"""
    
    def __init__(self, config, remote_port=None, is_desktop_mode=False, log_file=None, no_log_pane=False):
        # Log scroll state
        self.log_scroll_offset = 0
        
        # Track log updates for redraw triggering
        self.has_new_messages = False
        self.last_message_count = 0
        
        # Logger caching - stores created loggers by name
        self._loggers = {}
        
        # Create a root logger for stream capture routing
        # This logger will be used by LogCapture to route stdout/stderr through the handler pipeline
        self._stream_logger = logging.getLogger("TFM_STREAM_CAPTURE")
        self._stream_logger.setLevel(logging.DEBUG)  # Accept all levels
        self._stream_logger.propagate = False
        
        # Store configuration for handler management
        max_log_messages = config.MAX_LOG_MESSAGES
        self._config = LoggingConfig()
        self._config.max_log_messages = max_log_messages
        self._config.remote_monitoring_enabled = remote_port is not None
        self._config.remote_monitoring_port = remote_port
        # Enable stream output in desktop mode, disable in terminal mode
        self._config.stream_output_enabled = is_desktop_mode
        # Configure file logging
        self._config.file_logging_enabled = log_file is not None
        self._config.file_logging_path = log_file
        # Configure log pane (disabled if no_log_pane is True)
        self._config.log_pane_enabled = not no_log_pane
        
        # Log level configuration
        # Global default level (defaults to INFO)
        self._default_log_level = logging.INFO
        # Per-logger level overrides (logger_name -> level)
        self._logger_levels = {}
        
        # Handler instances
        self._log_pane_handler = None
        self._stream_output_handler = None
        self._remote_monitoring_handler = None
        self._file_logging_handler = None
        
        # Store desktop mode flag
        self.is_desktop_mode = is_desktop_mode
        
        # Store original streams
        self.original_stdout = sys.stdout
        self.original_stderr = sys.stderr
        
        # Redirect stdout and stderr
        sys.stdout = LogCapture("STDOUT", self.original_stdout, is_desktop_mode, logger=self._stream_logger)
        sys.stderr = LogCapture("STDERR", self.original_stderr, is_desktop_mode, logger=self._stream_logger)
        
        # Initialize handlers based on configuration
        # This creates the LogPaneHandler by default unless no_log_pane is True
        self.configure_handlers()
    
    def configure_handlers(self, 
                          log_pane_enabled: Optional[bool] = None,
                          stream_output_enabled: Optional[bool] = None,
                          remote_enabled: Optional[bool] = None):
        """
        Configure which handlers are active.
        Supports dynamic reconfiguration without restart.
        
        Args:
            log_pane_enabled: Enable log pane display (None = keep current)
            stream_output_enabled: Enable original stream output (None = keep current)
            remote_enabled: Enable remote monitoring (None = keep current)
        """
        # Update configuration
        if log_pane_enabled is not None:
            self._config.log_pane_enabled = log_pane_enabled
        if stream_output_enabled is not None:
            self._config.stream_output_enabled = stream_output_enabled
        if remote_enabled is not None:
            self._config.remote_monitoring_enabled = remote_enabled
        
        # Configure log pane handler
        if self._config.log_pane_enabled:
            if self._log_pane_handler is None:
                # Create new handler
                self._log_pane_handler = LogPaneHandler(max_messages=self._config.max_log_messages)
                # Add to stream logger
                if self._log_pane_handler not in self._stream_logger.handlers:
                    self._stream_logger.addHandler(self._log_pane_handler)
                # Add to all existing loggers
                for logger in self._loggers.values():
                    if self._log_pane_handler not in logger.handlers:
                        logger.addHandler(self._log_pane_handler)
        else:
            if self._log_pane_handler is not None:
                # Remove from stream logger
                if self._log_pane_handler in self._stream_logger.handlers:
                    self._stream_logger.removeHandler(self._log_pane_handler)
                # Remove from all existing loggers
                for logger in self._loggers.values():
                    if self._log_pane_handler in logger.handlers:
                        logger.removeHandler(self._log_pane_handler)
                self._log_pane_handler = None
        
        # Configure stream output handler
        if self._config.stream_output_enabled:
            if self._stream_output_handler is None:
                # Create new handler
                self._stream_output_handler = StreamOutputHandler(self.original_stdout)
                # Add to stream logger
                if self._stream_output_handler not in self._stream_logger.handlers:
                    self._stream_logger.addHandler(self._stream_output_handler)
                # Add to all existing loggers
                for logger in self._loggers.values():
                    if self._stream_output_handler not in logger.handlers:
                        logger.addHandler(self._stream_output_handler)
        else:
            if self._stream_output_handler is not None:
                # Remove from stream logger
                if self._stream_output_handler in self._stream_logger.handlers:
                    self._stream_logger.removeHandler(self._stream_output_handler)
                # Remove from all existing loggers
                for logger in self._loggers.values():
                    if self._stream_output_handler in logger.handlers:
                        logger.removeHandler(self._stream_output_handler)
                self._stream_output_handler = None
        
        # Configure remote monitoring handler
        if self._config.remote_monitoring_enabled:
            if self._remote_monitoring_handler is None and self._config.remote_monitoring_port:
                # Create new handler
                self._remote_monitoring_handler = RemoteMonitoringHandler(self._config.remote_monitoring_port)
                # Start the server
                self._remote_monitoring_handler.start_server()
                # Add to stream logger
                if self._remote_monitoring_handler not in self._stream_logger.handlers:
                    self._stream_logger.addHandler(self._remote_monitoring_handler)
                # Add to all existing loggers
                for logger in self._loggers.values():
                    if self._remote_monitoring_handler not in logger.handlers:
                        logger.addHandler(self._remote_monitoring_handler)
        else:
            if self._remote_monitoring_handler is not None:
                # Stop the server
                self._remote_monitoring_handler.stop_server()
                # Remove from stream logger
                if self._remote_monitoring_handler in self._stream_logger.handlers:
                    self._stream_logger.removeHandler(self._remote_monitoring_handler)
                # Remove from all existing loggers
                for logger in self._loggers.values():
                    if self._remote_monitoring_handler in logger.handlers:
                        logger.removeHandler(self._remote_monitoring_handler)
                self._remote_monitoring_handler = None
        
        # Configure file logging handler
        if self._config.file_logging_enabled:
            if self._file_logging_handler is None and self._config.file_logging_path:
                # Create new handler
                self._file_logging_handler = FileLoggingHandler(self._config.file_logging_path)
                # Add to stream logger
                if self._file_logging_handler not in self._stream_logger.handlers:
                    self._stream_logger.addHandler(self._file_logging_handler)
                # Add to all existing loggers
                for logger in self._loggers.values():
                    if self._file_logging_handler not in logger.handlers:
                        logger.addHandler(self._file_logging_handler)
        else:
            if self._file_logging_handler is not None:
                # Close the file
                self._file_logging_handler.close()
                # Remove from stream logger
                if self._file_logging_handler in self._stream_logger.handlers:
                    self._stream_logger.removeHandler(self._file_logging_handler)
                # Remove from all existing loggers
                for logger in self._loggers.values():
                    if self._file_logging_handler in logger.handlers:
                        logger.removeHandler(self._file_logging_handler)
                self._file_logging_handler = None
    
    def _configure_pending_logger(self, name: str, logger: logging.Logger):
        """
        Configure a pending logger with handlers.
        
        This is called by set_log_manager() to attach handlers to loggers
        that were created before LogManager initialization.
        
        Args:
            name: Logger name
            logger: Logger instance to configure
        """
        # Set level based on configuration
        # Check for per-logger override first, then use default
        if name in self._logger_levels:
            logger.setLevel(self._logger_levels[name])
        else:
            logger.setLevel(self._default_log_level)
        
        # Attach configured handlers based on current configuration
        if self._log_pane_handler is not None:
            logger.addHandler(self._log_pane_handler)
        if self._stream_output_handler is not None:
            logger.addHandler(self._stream_output_handler)
        if self._remote_monitoring_handler is not None:
            logger.addHandler(self._remote_monitoring_handler)
        if self._file_logging_handler is not None:
            logger.addHandler(self._file_logging_handler)
        
        # Cache the logger
        self._loggers[name] = logger
    
    def getLogger(self, name: str) -> logging.Logger:
        """
        Get or create a logger with TFM handlers configured.
        
        Returns existing logger if name was already used. This ensures that
        multiple calls with the same name return the same Logger instance.
        
        TFM creates multiple loggers for different purposes:
        - "Main": Main application logging
        - "FileOp": File operation logging
        - "DirDiff": Directory diff viewer logging
        - "Archive": Archive operations logging
        - etc.
        
        Args:
            name: Logger name (e.g., "Main", "FileOp", "DirDiff")
            
        Returns:
            Configured logging.Logger instance (existing or newly created)
        """
        # Return cached logger if it exists
        if name in self._loggers:
            return self._loggers[name]
        
        # Create new logger using Python's standard logging
        logger = logging.getLogger(name)
        
        # Set level based on configuration
        # Check for per-logger override first, then use default
        if name in self._logger_levels:
            logger.setLevel(self._logger_levels[name])
        else:
            logger.setLevel(self._default_log_level)
        
        # Prevent propagation to root logger to avoid duplicate messages
        logger.propagate = False
        
        # Attach configured handlers based on current configuration
        if self._log_pane_handler is not None:
            logger.addHandler(self._log_pane_handler)
        if self._stream_output_handler is not None:
            logger.addHandler(self._stream_output_handler)
        if self._remote_monitoring_handler is not None:
            logger.addHandler(self._remote_monitoring_handler)
        if self._file_logging_handler is not None:
            logger.addHandler(self._file_logging_handler)
        
        # Cache the logger
        self._loggers[name] = logger
        
        return logger
    
    def set_default_log_level(self, level: int):
        """
        Set the global default log level for all loggers.
        
        This affects all loggers that don't have a per-logger override.
        Existing loggers without overrides will be updated to the new level.
        
        Args:
            level: Log level (logging.DEBUG, INFO, WARNING, ERROR, CRITICAL)
        """
        self._default_log_level = level
        
        # Update existing loggers that don't have per-logger overrides
        for name, logger in self._loggers.items():
            if name not in self._logger_levels:
                logger.setLevel(level)
    
    def set_logger_level(self, logger_name: str, level: int):
        """
        Set the log level for a specific logger (per-logger override).
        
        This overrides the global default level for the specified logger.
        If the logger already exists, its level is updated immediately.
        If the logger doesn't exist yet, the override is stored and will
        be applied when the logger is created.
        
        Args:
            logger_name: Name of the logger to configure
            level: Log level (logging.DEBUG, INFO, WARNING, ERROR, CRITICAL)
        """
        self._logger_levels[logger_name] = level
        
        # Update existing logger if it exists
        if logger_name in self._loggers:
            self._loggers[logger_name].setLevel(level)
    
    def get_logger_level(self, logger_name: str) -> int:
        """
        Get the effective log level for a logger.
        
        Returns the per-logger override if set, otherwise the default level.
        
        Args:
            logger_name: Name of the logger
            
        Returns:
            Log level (logging.DEBUG, INFO, WARNING, ERROR, CRITICAL)
        """
        return self._logger_levels.get(logger_name, self._default_log_level)
    
    def clear_logger_level(self, logger_name: str):
        """
        Clear the per-logger level override for a specific logger.
        
        After clearing, the logger will use the global default level.
        If the logger exists, its level is updated to the default immediately.
        
        Args:
            logger_name: Name of the logger to clear override for
        """
        if logger_name in self._logger_levels:
            del self._logger_levels[logger_name]
            
            # Update existing logger to use default level
            if logger_name in self._loggers:
                self._loggers[logger_name].setLevel(self._default_log_level)
    
    def set_log_pane_visible(self, visible: bool):
        """
        Set whether the log pane is visible.
        
        When set to False, the LogPaneHandler skips expensive formatting operations
        for performance. Messages are still stored and will be formatted when the
        pane becomes visible again.
        
        Args:
            visible: True if log pane is visible, False otherwise
        """
        if self._log_pane_handler is not None:
            self._log_pane_handler.set_visible(visible)
    
    @property
    def log_pane_handler(self):
        """Get the log pane handler instance."""
        return self._log_pane_handler
    
    @property
    def stream_output_handler(self):
        """Get the stream output handler instance."""
        return self._stream_output_handler
    
    @property
    def remote_handler(self):
        """Get the remote monitoring handler instance."""
        return self._remote_monitoring_handler
    
    def has_log_updates(self):
        """Check if there are new log messages since last check"""
        if self._log_pane_handler is None:
            return False
        current_count = len(self._log_pane_handler.messages)
        if current_count != self.last_message_count or self.has_new_messages:
            return True
        return False
    
    def mark_log_updates_processed(self):
        """Mark that log updates have been processed (redraw completed)"""
        if self._log_pane_handler is None:
            return
        self.has_new_messages = False
        self.last_message_count = len(self._log_pane_handler.messages)
    
    def add_message(self, source, message):
        """
        Add a message directly to the log (backward compatibility method).
        
        This method maintains backward compatibility with existing code that uses
        add_message() instead of getLogger(). Messages are routed through the
        new logging infrastructure to ensure consistent handling.
        
        Args:
            source: Message source identifier (e.g., "System", "Config", "FileOp")
            message: Message text
        """
        # Route through logging infrastructure for consistent handling
        # Create a LogRecord with appropriate level based on source
        # Use INFO level for most sources, WARNING for error-related sources
        if source.upper() in ("ERROR", "STDERR"):
            level = logging.WARNING
        else:
            level = logging.INFO
        
        # Requirement 11.1: Performance optimization - check if level is enabled
        # Skip expensive LogRecord creation if level is disabled
        if not self._stream_logger.isEnabledFor(level):
            return
        
        # Create LogRecord
        record = logging.LogRecord(
            name=source,  # Use source as logger name
            level=level,
            pathname="",
            lineno=0,
            msg=message,
            args=(),
            exc_info=None
        )
        
        # Mark this as NOT a stream capture (it's a direct log message)
        # This ensures it gets formatted like a logger message, not stdout/stderr
        record.is_stream_capture = False
        
        # Route through the stream logger's handler pipeline
        # This ensures the message goes through all configured handlers
        # (LogPaneHandler, StreamOutputHandler, RemoteMonitoringHandler)
        self._stream_logger.handle(record)
    
    def add_startup_messages(self, version, github_url, app_name):
        """
        Add startup messages directly to log pane.
        
        Routes through logging infrastructure for consistent handling.
        
        Args:
            version: Application version string
            github_url: GitHub repository URL
            app_name: Application name
        """
        # Use add_message() which now routes through logging infrastructure
        self.add_message("System", f"TFM {version}")
        self.add_message("System", f"GitHub: {github_url}")
        self.add_message("System", f"{app_name} started successfully")
        self.add_message("Config", "Configuration loaded")
    
    def get_log_scroll_percentage(self, display_height=None):
        """Calculate the current log scroll position as a percentage"""
        total_messages = len(self._log_pane_handler.messages)
        
        if total_messages <= 1:
            return 0
        
        # Calculate max scroll based on display height if available
        if display_height is not None:
            max_scroll = max(0, total_messages - display_height)
        else:
            # Fallback to conservative estimate
            max_scroll = max(0, total_messages - 1)
        
        if max_scroll == 0:
            return 0
        
        # Calculate percentage
        percentage = (self.log_scroll_offset / max_scroll) * 100
        return max(0, min(100, percentage))
    
    def scroll_log_up(self, lines=1):
        """Scroll log up by specified number of lines (toward older messages)"""
        total_messages = len(self._log_pane_handler.messages)
        
        if total_messages > 0:
            # Allow scrolling up to the total number of messages
            # The draw method will cap this properly based on display height
            self.log_scroll_offset += lines
            return True
        return False
    
    def scroll_log_down(self, lines=1):
        """Scroll log down by specified number of lines (toward newer messages)"""
        if self.log_scroll_offset > 0:
            self.log_scroll_offset = max(0, self.log_scroll_offset - lines)
            return True
        return False
    
    def get_log_messages(self):
        """
        Get all log messages as a list of formatted strings (backward compatibility).
        
        This method is provided for backward compatibility with tests that expect
        a simple list of message strings. In production, messages are accessed
        through the handler's get_messages() method which returns (formatted, record) tuples.
        
        Returns:
            List of formatted message strings
        """
        # Get messages from handler and extract just the formatted strings
        handler_messages = self._log_pane_handler.get_messages()
        return [formatted_msg for formatted_msg, record in handler_messages]
    
    def get_visible_log_text(self, display_height):
        """
        Get visible log lines as text for clipboard copy.
        
        Returns the currently visible log lines based on scroll position,
        with line wrapping applied as it appears on screen.
        
        Args:
            display_height: Number of lines visible in the log pane
            
        Returns:
            String containing visible log lines (one per line)
        """
        if self._log_pane_handler is None or display_height <= 0:
            return ""
        
        # Get all messages
        handler_messages = self._log_pane_handler.get_messages()
        total_messages = len(handler_messages)
        
        if total_messages == 0:
            return ""
        
        # For clipboard copy, we don't need to wrap - just get the visible messages
        # Calculate which messages are visible based on scroll offset
        max_scroll = max(0, total_messages - display_height)
        scroll_offset = min(self.log_scroll_offset, max_scroll)
        
        start_idx = max(0, total_messages - display_height - scroll_offset)
        end_idx = min(total_messages, start_idx + display_height)
        
        visible_messages = handler_messages[start_idx:end_idx]
        
        # Extract formatted text from tuples
        lines = [formatted_msg for formatted_msg, record in visible_messages]
        
        return '\n'.join(lines)
    
    def get_all_log_text(self):
        """
        Get all log lines as text for clipboard copy.
        
        Returns all log messages including those not currently visible.
        
        Returns:
            String containing all log lines (one per line)
        """
        if self._log_pane_handler is None:
            return ""
        
        # Get all messages
        handler_messages = self._log_pane_handler.get_messages()
        
        if not handler_messages:
            return ""
        
        # Extract formatted text from tuples
        lines = [formatted_msg for formatted_msg, record in handler_messages]
        
        return '\n'.join(lines)
    
    def _wrap_line(self, text, width):
        """
        Wrap a single line of text to fit within the specified width.
        
        Args:
            text: Text to wrap
            width: Maximum width per line
            
        Returns:
            List of wrapped lines
        """
        if len(text) <= width:
            return [text]
        
        wrapped = []
        while text:
            if len(text) <= width:
                wrapped.append(text)
                break
            else:
                # Split at width
                wrapped.append(text[:width])
                text = text[width:]
        
        return wrapped
    
    def draw_log_pane(self, renderer, y_start, height, width):
        """Draw the log pane at the specified position with line wrapping"""
        if height <= 0:
            return
            
        try:
            # Draw log messages (no header)
            display_height = height  # Use full height for messages
            
            # Get messages from LogPaneHandler (list of (formatted_message, record) tuples)
            handler_messages = self._log_pane_handler.get_messages()
            total_messages = len(handler_messages)
            
            # Reserve space for scrollbar if we have messages
            # We'll calculate total wrapped lines for accurate scrollbar
            scrollbar_width = calculate_scrollbar_width(total_messages, display_height)
            content_width = width - scrollbar_width
            
            if total_messages > 0 and display_height > 0:
                # Wrap all messages and create a flat list of (wrapped_line, record) tuples
                wrapped_lines = []
                for formatted_message, record in handler_messages:
                    lines = self._wrap_line(formatted_message, content_width)
                    for line in lines:
                        wrapped_lines.append((line, record))
                
                total_wrapped_lines = len(wrapped_lines)
                
                # Recalculate scrollbar width based on wrapped lines
                scrollbar_width = calculate_scrollbar_width(total_wrapped_lines, display_height)
                
                # If scrollbar width changed, re-wrap with new content width
                new_content_width = width - scrollbar_width
                if new_content_width != content_width:
                    content_width = new_content_width
                    wrapped_lines = []
                    for formatted_message, record in handler_messages:
                        lines = self._wrap_line(formatted_message, content_width)
                        for line in lines:
                            wrapped_lines.append((line, record))
                    total_wrapped_lines = len(wrapped_lines)
                
                # Calculate which wrapped lines to show
                # Cap scroll offset to prevent scrolling beyond available content
                max_scroll = max(0, total_wrapped_lines - display_height)
                self.log_scroll_offset = min(self.log_scroll_offset, max_scroll)
                
                start_idx = max(0, total_wrapped_lines - display_height - self.log_scroll_offset)
                end_idx = min(total_wrapped_lines, start_idx + display_height)
                
                lines_to_show = wrapped_lines[start_idx:end_idx]
                
                for i, (wrapped_line, record) in enumerate(lines_to_show):
                    if i >= display_height:
                        break
                        
                    y = y_start + i
                    if y >= y_start + height:
                        break
                    
                    # Get color from handler based on record
                    color_pair, attributes = self._log_pane_handler.get_color_for_record(record)
                    renderer.draw_text(y, 0, wrapped_line.ljust(content_width)[:content_width], color_pair=color_pair, attributes=attributes)
                
                # Draw scrollbar if needed using unified implementation
                # Use inverted=True because scroll_offset=0 means bottom (newest messages)
                if scrollbar_width > 0:
                    draw_scrollbar(renderer, y_start, width - 1, height, 
                                 total_wrapped_lines, self.log_scroll_offset, inverted=True)
            
        except Exception:
            pass  # Ignore drawing errors
        finally:
            # Always mark log updates as processed when draw_log_pane is called
            # This ensures updates are marked as processed even if drawing fails
            self.mark_log_updates_processed()
    

    
    def stop_remote_server(self):
        """
        Stop the remote monitoring server (backward compatibility method).
        
        This method maintains backward compatibility with existing code.
        Remote monitoring is now handled by RemoteMonitoringHandler.
        """
        if self._remote_monitoring_handler:
            self._remote_monitoring_handler.stop_server()
    
    def restore_stdio(self):
        """Restore stdout/stderr to original state"""
        if hasattr(self, 'original_stdout') and sys.stdout != self.original_stdout:
            sys.stdout = self.original_stdout
        if hasattr(self, 'original_stderr') and sys.stderr != self.original_stderr:
            sys.stderr = self.original_stderr
    
    def __del__(self):
        """Cleanup when object is destroyed"""
        # Stop remote monitoring handler if active
        if hasattr(self, '_remote_monitoring_handler') and self._remote_monitoring_handler:
            self._remote_monitoring_handler.stop_server()
        
        # Close file logging handler if active
        if hasattr(self, '_file_logging_handler') and self._file_logging_handler:
            self._file_logging_handler.close()
        
        # Restore stdout/stderr
        self.restore_stdio()


# Module-level singleton instance
_log_manager_instance: Optional[LogManager] = None

# Pending loggers dictionary - stores loggers created before LogManager initialization
# Key: logger name, Value: logger instance
_pending_loggers: Dict[str, logging.Logger] = {}


def set_log_manager(log_manager: LogManager):
    """
    Set the global LogManager instance.
    
    This should be called once during application initialization.
    When called, all pending loggers will have their handlers attached.
    
    Args:
        log_manager: The LogManager instance to use globally
    """
    global _log_manager_instance
    _log_manager_instance = log_manager
    
    # Attach handlers to all pending loggers
    for name, logger in _pending_loggers.items():
        # Configure the pending logger with handlers
        _log_manager_instance._configure_pending_logger(name, logger)
    
    # Clear pending loggers dictionary since they're now configured
    _pending_loggers.clear()


def getLogger(name: str) -> logging.Logger:
    """
    Get or create a logger with TFM handlers configured.
    
    This is a module-level function that can be called without a LogManager instance.
    If a LogManager has been set via set_log_manager(), it will use that instance.
    Otherwise, it creates a "pending" logger without handlers that will be configured
    when LogManager is initialized.
    
    Pending loggers are stored in a dictionary so that multiple calls with the same
    name return the same logger instance, ensuring consistency.
    
    Args:
        name: Logger name (e.g., "Main", "FileOp", "Archive")
        
    Returns:
        Configured logging.Logger instance (or pending logger if LogManager not yet initialized)
    """
    if _log_manager_instance is not None:
        return _log_manager_instance.getLogger(name)
    else:
        # No LogManager available yet - create or return pending logger
        if name in _pending_loggers:
            # Return existing pending logger
            return _pending_loggers[name]
        
        # Create new pending logger without handlers
        logger = logging.getLogger(name)
        logger.setLevel(logging.INFO)  # Default level, will be updated when LogManager is created
        logger.propagate = False
        # Don't add any handlers - they will be added when LogManager is initialized
        
        # Store in pending loggers dictionary
        _pending_loggers[name] = logger
        
        return logger
